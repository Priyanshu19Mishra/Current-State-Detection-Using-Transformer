# Current-State-Detection-Using-Transformer
(A comparitive analysis between GRU and Transformer) 

This repository is in continuation of the previous work on the "Current State Detection". The Previous work was based on the architecture of 
GRU, that worked on the sequential data in the text form. 
Optimizing the processing further, in this repository, we are working with the another powerful architecture for the textual data in the 
sequential formatting. Now we will be working with the "Transformers". The architecture of the Transformer has been added in the repository. 

Transformers are well known for thier workings with the long sequential textual data due to their remembering capacities. 

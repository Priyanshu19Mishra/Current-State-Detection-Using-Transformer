Current-State-Detection-Using-Transformer
(A comparitive analysis between GRU and Transformer) 

This repository is in continuation of the previous work on the "Current State Detection". The Previous work was based on the architecture of 
GRU, that worked on the sequential data in the text form. 
Optimizing the processing further, in this repository, we are working with the another powerful architecture for the textual data in the 
sequential formatting. Now we will be working with the "Transformers". The architecture of the Transformer has been added in the repository. 

Transformers are well known for thier workings with the long sequential textual data due to their remembering capacities. Looking to this 
promising approach of the transformers, it has been in used in place of GRU. 

This approach using transformer, works on the same classes/ labels as GRU worked on. 
The nine labels are
1. Stress
2. No stress
3. Depression
4. No depression
5. Bi-polar Disorder
6. Personality disorder
7. Mental
8. Non-Mental
9. Anxiety

The result and the performaance of the model has been shared in the repository with multiple files. Images of the distribution of the  model
along with the performance of the model has been shared in the repository. 
The main source code file has been added in the repo with the title of "Psychology mood detection using transformer" the file contains the implementation.
The main task involves the integration of the dataset from the diversed categories. The data from the various categories were integrated into a single large 
dataset.
